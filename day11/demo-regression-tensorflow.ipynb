{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression and Classification Using Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow can be used for both linear regression and classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression using tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start by loading the necessary libraries, creating a graph, and loading the data:\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "from tensorflow.python.framework import ops\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', -1)\n",
    "\n",
    "ops.reset_default_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../datasets/housing-prices/train.csv')\n",
    "test = pd.read_csv('../datasets/housing-prices/test.csv')\n",
    "testID = test['Id']\n",
    "\n",
    "y = np.log1p(train['SalePrice'].values)\n",
    "data = pd.concat([train.drop('SalePrice', axis=1), test], keys=['train', 'test'])\n",
    "data.drop(['Id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>HouseStyle</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>RoofStyle</th>\n",
       "      <th>RoofMatl</th>\n",
       "      <th>Exterior1st</th>\n",
       "      <th>Exterior2nd</th>\n",
       "      <th>MasVnrType</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>ExterCond</th>\n",
       "      <th>Foundation</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>Heating</th>\n",
       "      <th>HeatingQC</th>\n",
       "      <th>CentralAir</th>\n",
       "      <th>Electrical</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Functional</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>196.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>706</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>856</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>1710</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>8</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>548</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Veenker</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>978</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>284</td>\n",
       "      <td>1262</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>162.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Mn</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>486</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>434</td>\n",
       "      <td>920</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>1786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>608</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>Wd Sdng</td>\n",
       "      <td>Wd Shng</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>BrkTil</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>No</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>216</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>540</td>\n",
       "      <td>756</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>1717</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>7</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>3</td>\n",
       "      <td>642</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NoRidge</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>350.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Av</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>655</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>490</td>\n",
       "      <td>1145</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>2198</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>9</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>3</td>\n",
       "      <td>836</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape LandContour Utilities LotConfig LandSlope Neighborhood Condition1 Condition2 BldgType HouseStyle  OverallQual  OverallCond  YearBuilt  YearRemodAdd RoofStyle RoofMatl Exterior1st Exterior2nd MasVnrType  MasVnrArea ExterQual ExterCond Foundation BsmtQual BsmtCond BsmtExposure BsmtFinType1  BsmtFinSF1 BsmtFinType2  BsmtFinSF2  BsmtUnfSF  TotalBsmtSF Heating HeatingQC CentralAir Electrical  1stFlrSF  2ndFlrSF  LowQualFinSF  GrLivArea  BsmtFullBath  BsmtHalfBath  FullBath  HalfBath  BedroomAbvGr  KitchenAbvGr KitchenQual  TotRmsAbvGrd Functional  Fireplaces FireplaceQu GarageType  GarageYrBlt GarageFinish  GarageCars  GarageArea GarageQual GarageCond PavedDrive  WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea PoolQC Fence MiscFeature  MiscVal  MoSold  YrSold SaleType SaleCondition  SalePrice\n",
       "0  1   60          RL       65.0         8450     Pave   NaN   Reg      Lvl         AllPub    Inside    Gtl       CollgCr      Norm       Norm       1Fam     2Story     7            5            2003       2003          Gable     CompShg  VinylSd     VinylSd     BrkFace    196.0       Gd        TA        PConc      Gd       TA       No           GLQ          706         Unf          0           150        856          GasA    Ex        Y          SBrkr      856       854       0             1710       1             0             2         1         3             1             Gd          8             Typ        0           NaN         Attchd     2003.0       RFn          2           548         TA         TA         Y          0           61           0              0          0            0         NaN    NaN   NaN         0        2       2008    WD       Normal        208500   \n",
       "1  2   20          RL       80.0         9600     Pave   NaN   Reg      Lvl         AllPub    FR2       Gtl       Veenker      Feedr      Norm       1Fam     1Story     6            8            1976       1976          Gable     CompShg  MetalSd     MetalSd     None       0.0         TA        TA        CBlock     Gd       TA       Gd           ALQ          978         Unf          0           284        1262         GasA    Ex        Y          SBrkr      1262      0         0             1262       0             1             2         0         3             1             TA          6             Typ        1           TA          Attchd     1976.0       RFn          2           460         TA         TA         Y          298         0            0              0          0            0         NaN    NaN   NaN         0        5       2007    WD       Normal        181500   \n",
       "2  3   60          RL       68.0         11250    Pave   NaN   IR1      Lvl         AllPub    Inside    Gtl       CollgCr      Norm       Norm       1Fam     2Story     7            5            2001       2002          Gable     CompShg  VinylSd     VinylSd     BrkFace    162.0       Gd        TA        PConc      Gd       TA       Mn           GLQ          486         Unf          0           434        920          GasA    Ex        Y          SBrkr      920       866       0             1786       1             0             2         1         3             1             Gd          6             Typ        1           TA          Attchd     2001.0       RFn          2           608         TA         TA         Y          0           42           0              0          0            0         NaN    NaN   NaN         0        9       2008    WD       Normal        223500   \n",
       "3  4   70          RL       60.0         9550     Pave   NaN   IR1      Lvl         AllPub    Corner    Gtl       Crawfor      Norm       Norm       1Fam     2Story     7            5            1915       1970          Gable     CompShg  Wd Sdng     Wd Shng     None       0.0         TA        TA        BrkTil     TA       Gd       No           ALQ          216         Unf          0           540        756          GasA    Gd        Y          SBrkr      961       756       0             1717       1             0             1         0         3             1             Gd          7             Typ        1           Gd          Detchd     1998.0       Unf          3           642         TA         TA         Y          0           35           272            0          0            0         NaN    NaN   NaN         0        2       2006    WD       Abnorml       140000   \n",
       "4  5   60          RL       84.0         14260    Pave   NaN   IR1      Lvl         AllPub    FR2       Gtl       NoRidge      Norm       Norm       1Fam     2Story     8            5            2000       2000          Gable     CompShg  VinylSd     VinylSd     BrkFace    350.0       Gd        TA        PConc      Gd       TA       Av           GLQ          655         Unf          0           490        1145         GasA    Ex        Y          SBrkr      1145      1053      0             2198       1             0             2         1         4             1             Gd          9             Typ        1           TA          Attchd     2000.0       RFn          3           836         TA         TA         Y          192         84           0              0          0            0         NaN    NaN   NaN         0        12      2008    WD       Normal        250000   "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['MSSubClass'] = data['MSSubClass'].map(lambda x: 'MSSubClass_'+str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSSubClass = pd.get_dummies(data['MSSubClass'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSZoning = pd.get_dummies(data['MSZoning'])\n",
    "MSZoning.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['LotFrontage'].fillna(np.nanmedian(data['LotFrontage']), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins = [0, 25, 30, 40, 50, 60, 70, 80, 100, 150, 200, 250, 350]\n",
    "LotFrontage_bins = pd.get_dummies(pd.cut(data['LotFrontage'], bins))\n",
    "LotFrontage_bins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2919,)\n",
      "(2919, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X = np.log10(data[\"LotArea\"]).values\n",
    "print(X.shape)\n",
    "             \n",
    "LotArea = StandardScaler().fit_transform(X.reshape(-1,1))\n",
    "print(LotArea.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Street = pd.get_dummies(data['Street'])\n",
    "Street.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LotShape = pd.get_dummies(data['LotShape'])\n",
    "LotShape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lvl    2622\n",
       "HLS    120 \n",
       "Bnk    117 \n",
       "Low    60  \n",
       "Name: LandContour, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['LandContour'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LandContour = pd.get_dummies(data['LandContour'])\n",
    "LandContour.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['LotFrontage', 'LotArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF',\n",
    "           '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
    "           'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'GarageArea', 'WoodDeckSF',\n",
    "           'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea']\n",
    "\n",
    "cat_cols = [col for col in data.columns.tolist() if col not in num_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 55)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(num_cols), len(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3273da33e1b74520b77cb7caea8259b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=55), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "data_cat = pd.DataFrame()\n",
    "for col in tqdm_notebook(cat_cols):\n",
    "    if data[col].isnull().sum() > 0:\n",
    "        data[col].fillna('UNK_'+col, inplace=True)\n",
    "    data[col] = data[col].map(lambda x: col+str(x))\n",
    "    mydf = pd.get_dummies(data[col])\n",
    "    if len(data_cat) == 0:\n",
    "        data_cat = mydf\n",
    "    else:\n",
    "        data_cat = pd.concat([data_cat, mydf], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 25, 30, 40, 50, 60, 70, 80, 100, 150, 200, 250, 350]\n",
    "data['LotFrontage'].fillna(np.nanmedian(data['LotFrontage']), inplace=True)\n",
    "columns = ['LotFrontage_bin'+str(x) for x in range(len(bins)-1)]\n",
    "LotFrontage_bins = pd.get_dummies(pd.cut(data['LotFrontage'], bins))\n",
    "LotFrontage_bins.columns = columns\n",
    "data_cat = pd.concat([data_cat, LotFrontage_bins], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols.remove('LotFrontage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num = data[num_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LotArea 1951\n",
      "BsmtFinSF1 992\n",
      "BsmtFinSF2 273\n",
      "BsmtUnfSF 1136\n",
      "TotalBsmtSF 1059\n",
      "1stFlrSF 1083\n",
      "2ndFlrSF 635\n",
      "LowQualFinSF 36\n",
      "GrLivArea 1292\n",
      "BsmtFullBath 5\n",
      "BsmtHalfBath 4\n",
      "FullBath 5\n",
      "HalfBath 3\n",
      "TotRmsAbvGrd 14\n",
      "Fireplaces 5\n",
      "GarageCars 7\n",
      "GarageArea 604\n",
      "WoodDeckSF 379\n",
      "OpenPorchSF 252\n",
      "EnclosedPorch 183\n",
      "3SsnPorch 31\n",
      "ScreenPorch 121\n",
      "PoolArea 14\n"
     ]
    }
   ],
   "source": [
    "for col in num_cols:\n",
    "    print(col, data_num[col].nunique(dropna=False))\n",
    "    data_num[col].fillna(np.nanmedian(data_num[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LotArea\n",
      "BsmtFinSF1\n",
      "BsmtFinSF1 368.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/pandas/core/generic.py:5434: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/pandas/core/generic.py:5434: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BsmtFinSF2\n",
      "BsmtFinSF2 0.0\n",
      "BsmtUnfSF\n",
      "BsmtUnfSF 467.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/pandas/core/generic.py:5434: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/pandas/core/generic.py:5434: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TotalBsmtSF\n",
      "TotalBsmtSF 989.5\n",
      "1stFlrSF\n",
      "2ndFlrSF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LowQualFinSF\n",
      "GrLivArea\n",
      "BsmtFullBath\n",
      "BsmtFullBath 0.0\n",
      "BsmtHalfBath\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/pandas/core/generic.py:5434: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/pandas/core/generic.py:5434: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BsmtHalfBath 0.0\n",
      "FullBath\n",
      "HalfBath\n",
      "TotRmsAbvGrd\n",
      "Fireplaces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/pandas/core/generic.py:5434: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GarageCars\n",
      "GarageCars 2.0\n",
      "GarageArea\n",
      "GarageArea 480.0\n",
      "WoodDeckSF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/pandas/core/generic.py:5434: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenPorchSF\n",
      "EnclosedPorch\n",
      "3SsnPorch\n",
      "ScreenPorch\n",
      "PoolArea\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/watts/anaconda3/envs/itv/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "for col in num_cols:\n",
    "    print(col)\n",
    "    if data_num[col].isnull().any() == True:\n",
    "        print(col, np.nanmedian(data_num[col]))\n",
    "        data_num[col].fillna(np.nanmedian(data_num[col]), inplace=True)\n",
    "    X = data_num[col].values\n",
    "    data_num[col] = StandardScaler().fit_transform(X.reshape(-1,1)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2919, 23), (2919, 1117))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_num.shape, data_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processed = pd.concat([data_num, data_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 1140)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12.24769912, 12.10901644, 12.31717117, ..., 12.49313327,\n",
       "       11.86446927, 11.90159023])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_vals = data_processed.values\n",
    "\n",
    "x_vals_train = x_vals[:len(train)]\n",
    "x_vals_test = x_vals[len(train):]\n",
    "\n",
    "X = x_vals_train\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2919, 1140), (1460,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_vals.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1168, 1140), (1460,), (292, 1140))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,y.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../cache/X_train', X_train)\n",
    "np.save('../cache/X_val', X_val)\n",
    "np.save('../cache/y_train', y_train)\n",
    "np.save('../cache/y_val', y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We declare our learning rate, batch size, placeholders, and model variables:\n",
    "learning_rate = 0.0005\n",
    "batch_size = 25\n",
    "x_data = tf.placeholder(shape=[None,X_train.shape[1]], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "A = tf.Variable(tf.random_normal(shape=[X_train.shape[1], 1], mean=0, stddev=1, dtype=tf.float32))\n",
    "b = tf.Variable(tf.random_normal(shape=[1,1], mean=0, stddev=1, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate = 0.05\n",
    "# batch_size = 25\n",
    "# x_data = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "# y_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "# A = tf.Variable(tf.random_normal(shape=[1,1]))\n",
    "# b = tf.Variable(tf.random_normal(shape=[1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we write the formula for the linear model, y=Ax+b:\n",
    "model_output = tf.add(tf.matmul(x_data, A), b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we declare our L2 loss function (which includes the mean over the batch),\n",
    "# initialize the variables, and declare our optimizer. Note that we chose 0.05 as our\n",
    "# learning rate:\n",
    "loss = tf.reduce_mean(tf.square(y_target - model_output))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "my_opt = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train_step = my_opt.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.1214571 ]\n",
      " [-0.8559874 ]\n",
      " [ 1.6588043 ]\n",
      " ...\n",
      " [-0.65630585]\n",
      " [-0.4111823 ]\n",
      " [-0.2326453 ]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33805653]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.22421933,  1.05520839, -0.29302528, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.29561488, -0.96913327, -0.29302528, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.17641094, -0.96913327, -0.29302528, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.25313262, -0.60246835, -0.29302528, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.32034336, -0.96913327, -0.29302528, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.82226804, -0.96913327, -0.29302528, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07949ee127a849d3aa146a4ee5d514b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #1000 A = [[ 0.48974478]\n",
      " [-0.12419165]\n",
      " [ 0.82702595]\n",
      " ...\n",
      " [-0.6324297 ]\n",
      " [-0.4111823 ]\n",
      " [-0.21832767]]b = [[0.9624538]]\n",
      "Loss = 20.910908\n",
      "Step #2000 A = [[ 0.3515749 ]\n",
      " [ 0.03470074]\n",
      " [ 0.4577966 ]\n",
      " ...\n",
      " [-0.6228576 ]\n",
      " [-0.4111823 ]\n",
      " [-0.20873918]]b = [[1.0075605]]\n",
      "Loss = 17.824255\n",
      "Step #3000 A = [[ 0.24128829]\n",
      " [ 0.06589257]\n",
      " [ 0.31792694]\n",
      " ...\n",
      " [-0.6213335 ]\n",
      " [-0.4111823 ]\n",
      " [-0.20007278]]b = [[1.0294656]]\n",
      "Loss = 9.725162\n",
      "Step #4000 A = [[ 0.19500169]\n",
      " [ 0.07976186]\n",
      " [ 0.2599054 ]\n",
      " ...\n",
      " [-0.6194118 ]\n",
      " [-0.4111823 ]\n",
      " [-0.19048332]]b = [[1.0541595]]\n",
      "Loss = 6.665202\n",
      "Step #5000 A = [[ 0.15584561]\n",
      " [ 0.08072476]\n",
      " [ 0.2442012 ]\n",
      " ...\n",
      " [-0.6169766 ]\n",
      " [-0.4111823 ]\n",
      " [-0.18112098]]b = [[1.0748761]]\n",
      "Loss = 10.466142\n",
      "Step #6000 A = [[ 0.15058102]\n",
      " [ 0.08054748]\n",
      " [ 0.23341753]\n",
      " ...\n",
      " [-0.6130693 ]\n",
      " [-0.4111823 ]\n",
      " [-0.17429607]]b = [[1.0850526]]\n",
      "Loss = 6.5910997\n",
      "Step #7000 A = [[ 0.16494745]\n",
      " [ 0.09234081]\n",
      " [ 0.23866084]\n",
      " ...\n",
      " [-0.6125618 ]\n",
      " [-0.4111823 ]\n",
      " [-0.16858369]]b = [[1.0949377]]\n",
      "Loss = 4.9249883\n",
      "Step #8000 A = [[ 0.14644092]\n",
      " [ 0.09834644]\n",
      " [ 0.23570698]\n",
      " ...\n",
      " [-0.6100157 ]\n",
      " [-0.4111823 ]\n",
      " [-0.16274771]]b = [[1.1077046]]\n",
      "Loss = 4.3456283\n",
      "Step #9000 A = [[ 0.11415361]\n",
      " [ 0.10709187]\n",
      " [ 0.22795193]\n",
      " ...\n",
      " [-0.60842866]\n",
      " [-0.4111823 ]\n",
      " [-0.15550423]]b = [[1.1116894]]\n",
      "Loss = 2.785749\n",
      "Step #10000 A = [[ 0.10168841]\n",
      " [ 0.10307039]\n",
      " [ 0.22402893]\n",
      " ...\n",
      " [-0.6068436 ]\n",
      " [-0.4111823 ]\n",
      " [-0.15154864]]b = [[1.123264]]\n",
      "Loss = 8.361899\n",
      "Step #11000 A = [[ 0.10662422]\n",
      " [ 0.10448658]\n",
      " [ 0.23007369]\n",
      " ...\n",
      " [-0.6033105 ]\n",
      " [-0.4111823 ]\n",
      " [-0.1479584 ]]b = [[1.1277653]]\n",
      "Loss = 3.780174\n",
      "Step #12000 A = [[ 0.09759466]\n",
      " [ 0.12900613]\n",
      " [ 0.23051907]\n",
      " ...\n",
      " [-0.59927064]\n",
      " [-0.4111823 ]\n",
      " [-0.14396767]]b = [[1.1308935]]\n",
      "Loss = 3.3219802\n",
      "Step #13000 A = [[ 0.07921562]\n",
      " [ 0.12557706]\n",
      " [ 0.23068684]\n",
      " ...\n",
      " [-0.59669244]\n",
      " [-0.4111823 ]\n",
      " [-0.14007711]]b = [[1.1400785]]\n",
      "Loss = 3.95001\n",
      "Step #14000 A = [[ 0.07478669]\n",
      " [ 0.13349164]\n",
      " [ 0.21959674]\n",
      " ...\n",
      " [-0.5927948 ]\n",
      " [-0.4111823 ]\n",
      " [-0.13399675]]b = [[1.1428897]]\n",
      "Loss = 3.6204202\n",
      "Step #15000 A = [[ 0.0972965 ]\n",
      " [ 0.13793918]\n",
      " [ 0.21716258]\n",
      " ...\n",
      " [-0.590463  ]\n",
      " [-0.4111823 ]\n",
      " [-0.13170008]]b = [[1.1487316]]\n",
      "Loss = 4.960192\n",
      "Step #16000 A = [[ 0.07967226]\n",
      " [ 0.1398193 ]\n",
      " [ 0.22774616]\n",
      " ...\n",
      " [-0.5879779 ]\n",
      " [-0.4111823 ]\n",
      " [-0.1284843 ]]b = [[1.1545765]]\n",
      "Loss = 3.0189111\n",
      "Step #17000 A = [[ 0.06610405]\n",
      " [ 0.14475133]\n",
      " [ 0.22048573]\n",
      " ...\n",
      " [-0.58414036]\n",
      " [-0.4111823 ]\n",
      " [-0.12560438]]b = [[1.1584736]]\n",
      "Loss = 3.7238107\n",
      "Step #18000 A = [[ 0.06420905]\n",
      " [ 0.15619431]\n",
      " [ 0.21251497]\n",
      " ...\n",
      " [-0.58172   ]\n",
      " [-0.4111823 ]\n",
      " [-0.12378863]]b = [[1.1635294]]\n",
      "Loss = 4.677153\n",
      "Step #19000 A = [[ 0.06376339]\n",
      " [ 0.15137894]\n",
      " [ 0.20890778]\n",
      " ...\n",
      " [-0.57776064]\n",
      " [-0.4111823 ]\n",
      " [-0.12120339]]b = [[1.1666325]]\n",
      "Loss = 2.0032775\n",
      "Step #20000 A = [[ 0.0687921 ]\n",
      " [ 0.165136  ]\n",
      " [ 0.21026975]\n",
      " ...\n",
      " [-0.5727293 ]\n",
      " [-0.4111823 ]\n",
      " [-0.11925941]]b = [[1.1721544]]\n",
      "Loss = 2.0541284\n",
      "Step #21000 A = [[ 0.04056257]\n",
      " [ 0.1588646 ]\n",
      " [ 0.21162234]\n",
      " ...\n",
      " [-0.5699652 ]\n",
      " [-0.4111823 ]\n",
      " [-0.11629207]]b = [[1.1740928]]\n",
      "Loss = 3.10588\n",
      "Step #22000 A = [[ 0.03741501]\n",
      " [ 0.15889984]\n",
      " [ 0.2045824 ]\n",
      " ...\n",
      " [-0.5670636 ]\n",
      " [-0.4111823 ]\n",
      " [-0.11408136]]b = [[1.1788563]]\n",
      "Loss = 3.690807\n",
      "Step #23000 A = [[ 0.04142131]\n",
      " [ 0.16936733]\n",
      " [ 0.19549789]\n",
      " ...\n",
      " [-0.5628302 ]\n",
      " [-0.4111823 ]\n",
      " [-0.11187834]]b = [[1.1876553]]\n",
      "Loss = 1.6593845\n",
      "Step #24000 A = [[ 0.04011267]\n",
      " [ 0.1675471 ]\n",
      " [ 0.19013399]\n",
      " ...\n",
      " [-0.56018454]\n",
      " [-0.4111823 ]\n",
      " [-0.10953979]]b = [[1.1884211]]\n",
      "Loss = 2.0655532\n",
      "Step #25000 A = [[ 0.03583886]\n",
      " [ 0.1717336 ]\n",
      " [ 0.18008259]\n",
      " ...\n",
      " [-0.55775934]\n",
      " [-0.4111823 ]\n",
      " [-0.10747234]]b = [[1.1943524]]\n",
      "Loss = 3.2019334\n",
      "Step #26000 A = [[ 0.04822595]\n",
      " [ 0.1709334 ]\n",
      " [ 0.18814988]\n",
      " ...\n",
      " [-0.55392194]\n",
      " [-0.4111823 ]\n",
      " [-0.1058127 ]]b = [[1.1959015]]\n",
      "Loss = 2.2065403\n",
      "Step #27000 A = [[ 0.03689564]\n",
      " [ 0.16950186]\n",
      " [ 0.18406136]\n",
      " ...\n",
      " [-0.5502374 ]\n",
      " [-0.4111823 ]\n",
      " [-0.10369353]]b = [[1.199234]]\n",
      "Loss = 1.3996248\n",
      "Step #28000 A = [[ 0.02930851]\n",
      " [ 0.170717  ]\n",
      " [ 0.17804001]\n",
      " ...\n",
      " [-0.54688865]\n",
      " [-0.4111823 ]\n",
      " [-0.10110674]]b = [[1.2013861]]\n",
      "Loss = 2.1801803\n",
      "Step #29000 A = [[ 0.04203807]\n",
      " [ 0.16878372]\n",
      " [ 0.18295631]\n",
      " ...\n",
      " [-0.5420279 ]\n",
      " [-0.4111823 ]\n",
      " [-0.09914548]]b = [[1.2063569]]\n",
      "Loss = 1.6988274\n",
      "Step #30000 A = [[ 0.04467875]\n",
      " [ 0.17923063]\n",
      " [ 0.17767923]\n",
      " ...\n",
      " [-0.5375115 ]\n",
      " [-0.4111823 ]\n",
      " [-0.09741458]]b = [[1.2092435]]\n",
      "Loss = 1.5096118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can now loop through and train the model on randomly selected batches. We will\n",
    "# run it for 100 loops and print out the variable and loss values every 25 iterations.\n",
    "# Note that here we are also saving the loss of every iteration so that we can view it\n",
    "# afterwards:\n",
    "loss_vec = []\n",
    "for i in tqdm_notebook(range(30000)):\n",
    "    rand_index = np.random.choice(len(X_train), size=batch_size)\n",
    "    rand_x = X_train[rand_index]\n",
    "    rand_y = y_train[rand_index].reshape(-1,1)\n",
    "    sess.run(train_step, feed_dict={x_data: rand_x, y_target:rand_y})\n",
    "    temp_loss = sess.run(loss, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "    loss_vec.append(temp_loss)\n",
    "    if (i+1)%1000==0:\n",
    "        print('Step #' + str(i+1) + ' A = ' + str(sess.run(A)) + 'b = ' + str(sess.run(b)))\n",
    "        print('Loss = ''' + str(temp_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_val = X_val.astype(np.float32)\n",
    "y_val_predicted = sess.run(tf.matmul(X_val, A) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-13.854455151883359"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(y_val, y_val_predicted)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start by loading the necessary libraries, creating a graph, and loading the data:\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "from tensorflow.python.framework import ops\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', -1)\n",
    "\n",
    "ops.reset_default_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('../cache/X_train.npy')\n",
    "X_val = np.load('../cache/X_val.npy')\n",
    "y_train = np.load('../cache/y_train.npy')\n",
    "y_val = np.load('../cache/y_val.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heaviside Step Function\n",
    "\n",
    "The Heaviside step function, or the unit step function, usually denoted by H or  (but sometimes u, 1 or ), is a discontinuous function, named after Oliver Heaviside (18501925), whose value is zero for negative argument and one for positive argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add the loss function, which is a modified continuous heavyside step function.\n",
    "# We also set the cutoff for lasso regression at 0.9 . This means that we want to restrict\n",
    "# the slope coefficient to be less than 0.9 . Use the following code:\n",
    "bach_size = 50\n",
    "x_data = tf.placeholder(shape=[None,X_train.shape[1]], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "reg_param = tf.placeholder(shape=[1,1], dtype=tf.float32)\n",
    "A = tf.Variable(tf.random_normal(shape=[X_train.shape[1], 1], dtype=tf.float32))\n",
    "b = tf.Variable(tf.random_normal(shape=[1,1], mean=0, stddev=1, dtype=tf.float32))\n",
    "\n",
    "# Declare Lasso loss function\n",
    "# Lasso Loss = L2_Loss + heavyside_step,\n",
    "# Where heavyside_step ~ 0 if A < constant, otherwise ~ 99\n",
    "lasso_param = tf.constant(0.9)\n",
    "heavyside_step = tf.truediv(1., tf.add(1., tf.exp(tf.multiply(-100.,tf.reduce_mean(tf.subtract(A, lasso_param))))))\n",
    "regularization_param = tf.multiply(heavyside_step, 99.)\n",
    "# model_output = tf.add(tf.add(tf.matmul(x_data, A), b), regularization_param)\n",
    "model_output = tf.add(tf.matmul(x_data, A), b)\n",
    "lasso_loss = tf.add(tf.reduce_mean(tf.square(y_target - model_output)),reg_param)\n",
    "\n",
    "learning_rate = 0.001\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "my_opt = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train_step = my_opt.minimize(lasso_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sess.run(A)\n",
    "# sess.run(heavyside_step)\n",
    "sess.run(regularization_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dd607b5fb4844b1a92c5217f11f4653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #10000 A = [[ 0.01745011]\n",
      " [-0.18922137]\n",
      " [-0.12209782]\n",
      " ...\n",
      " [ 0.44511452]\n",
      " [-1.1057391 ]\n",
      " [-0.6921445 ]]b = [[1.7665231]]\n",
      "Loss = [[3.3702471]]\n",
      "Step #20000 A = [[ 0.0148832 ]\n",
      " [-0.10084993]\n",
      " [-0.07006028]\n",
      " ...\n",
      " [ 0.4019568 ]\n",
      " [-1.1057391 ]\n",
      " [-0.69881916]]b = [[1.7931547]]\n",
      "Loss = [[1.3979422]]\n",
      "Step #30000 A = [[ 0.0078067 ]\n",
      " [-0.06836872]\n",
      " [-0.04086526]\n",
      " ...\n",
      " [ 0.35921973]\n",
      " [-1.1057391 ]\n",
      " [-0.6989342 ]]b = [[1.8102524]]\n",
      "Loss = [[1.49942]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_vec = []\n",
    "batch_size = 25\n",
    "for i in tqdm_notebook(range(30000)):\n",
    "    rand_index = np.random.choice(len(X_train), size=batch_size)\n",
    "    rand_x = X_train[rand_index]\n",
    "    rand_y = y_train[rand_index].reshape(-1,1)\n",
    "    reg_par = sess.run(regularization_param)\n",
    "    sess.run(train_step, feed_dict={x_data: rand_x, y_target:rand_y })\n",
    "    temp_loss = sess.run(lasso_loss, feed_dict={x_data: rand_x, y_target: rand_y, reg_param: reg_par.reshape(-1,1)})\n",
    "\n",
    "    loss_vec.append(temp_loss)\n",
    "    if (i+1)%10000==0:\n",
    "        print('Step #' + str(i+1) + ' A = ' + str(sess.run(A)) + 'b = ' + str(sess.run(b)))\n",
    "        print('Loss = ''' + str(temp_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.048774706635721"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val = X_val.astype(np.float32)\n",
    "y_val_predicted = sess.run(tf.matmul(X_val, A) + b)\n",
    "r2_score(y_val, y_val_predicted)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression using Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start by loading the necessary libraries, creating a graph, and loading the data:\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "from tensorflow.python.framework import ops\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', -1)\n",
    "\n",
    "ops.reset_default_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('../cache/X_train.npy')\n",
    "X_val = np.load('../cache/X_val.npy')\n",
    "y_train = np.load('../cache/y_train.npy')\n",
    "y_val = np.load('../cache/y_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add the loss function, which is a modified continuous heavyside step function.\n",
    "# We also set the cutoff for lasso regression at 0.9 . This means that we want to restrict\n",
    "# the slope coefficient to be less than 0.9 . Use the following code:\n",
    "bach_size = 50\n",
    "x_data = tf.placeholder(shape=[None,X_train.shape[1]], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "\n",
    "A = tf.Variable(tf.random_normal(shape=[X_train.shape[1], 1], dtype=tf.float32))\n",
    "b = tf.Variable(tf.random_normal(shape=[1,1], mean=0, stddev=1, dtype=tf.float32))\n",
    "model_output = tf.add(tf.matmul(x_data, A), b)\n",
    "\n",
    "ridge_param = tf.constant(1.)\n",
    "ridge_loss = tf.reduce_mean(tf.square(A))\n",
    "loss = tf.expand_dims(\n",
    "    tf.add(\n",
    "        tf.reduce_mean(\n",
    "            tf.square(y_target -model_output)), \n",
    "        tf.multiply(ridge_param, ridge_loss)), \n",
    "    0)\n",
    "\n",
    "learning_rate = 0.001\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "my_opt = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train_step = my_opt.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "550070cd2c2d4c96b6d6d55ba9c529be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #10000 A = [[ 8.3298311e-02]\n",
      " [-1.7279442e-01]\n",
      " [-7.0724869e-04]\n",
      " ...\n",
      " [ 1.0518183e+00]\n",
      " [ 8.6220197e-02]\n",
      " [-6.0501271e-01]]b = [[0.44074133]]\n",
      "Loss = [1.2208205]\n",
      "Step #20000 A = [[ 0.08151925]\n",
      " [-0.16896461]\n",
      " [ 0.00164573]\n",
      " ...\n",
      " [ 1.0452977 ]\n",
      " [ 0.08473008]\n",
      " [-0.60186017]]b = [[0.46807453]]\n",
      "Loss = [1.0673039]\n",
      "Step #30000 A = [[ 0.08028734]\n",
      " [-0.16173564]\n",
      " [ 0.00122472]\n",
      " ...\n",
      " [ 1.0422298 ]\n",
      " [ 0.08323997]\n",
      " [-0.596484  ]]b = [[0.49489278]]\n",
      "Loss = [0.97903097]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_vec = []\n",
    "batch_size = 100\n",
    "for i in tqdm_notebook(range(30000)):\n",
    "    rand_index = np.random.choice(len(X_train), size=batch_size)\n",
    "    rand_x = X_train[rand_index]\n",
    "    rand_y = y_train[rand_index].reshape(-1,1)\n",
    "    \n",
    "    sess.run(train_step, feed_dict={x_data: rand_x, y_target:rand_y })\n",
    "    temp_loss = sess.run(loss, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "\n",
    "    loss_vec.append(temp_loss)\n",
    "    if (i+1)%10000==0:\n",
    "        print('Step #' + str(i+1) + ' A = ' + str(sess.run(A)) + 'b = ' + str(sess.run(b)))\n",
    "        print('Loss = ''' + str(temp_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.332496080720992"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val = X_val.astype(np.float32)\n",
    "y_val_predicted = sess.run(tf.matmul(X_val, A) + b)\n",
    "r2_score(y_val, y_val_predicted)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential model\n",
    "\n",
    "The Keras Sequential model is a linear stack of layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense layer\n",
    "Dense implements the operation: output = activation(dot(input, kernel) + bias) where activation is the element-wise activation function passed as the activation argument, kernel is a weights matrix created by the layer, and bias is a bias vector created by the layer (only applicable if use_bias is True)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout\n",
    "\n",
    "Simply put, dropout refers to ignoring units (i.e. neurons) during the training phase of certain set of neurons which is chosen at random. By ignoring, I mean these units are not considered during a particular forward or backward pass.\n",
    "\n",
    "why do we need dropout at all? Why do we need to literally shut-down parts of a neural networks?\n",
    "\n",
    "The answer to these questions is to prevent over-fitting.\n",
    "\n",
    "A fully connected layer occupies most of the parameters, and hence, neurons develop co-dependency amongst each other during training which curbs the individual power of each neuron leading to over-fitting of training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "\n",
    "# the number of dense layers and number of dense neurons in by trial and error\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=1140))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(32))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('linear')) \n",
    "\n",
    "# For a mean squared error regression problem\n",
    "sgd = optimizers.SGD(lr=0.0035, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8cc805df28>"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=200, batch_size=32, validation_data=[X_val,y_val], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_predicted = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9003606291118122"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_val, y_val_predicted)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "itv",
   "language": "python",
   "name": "itv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
